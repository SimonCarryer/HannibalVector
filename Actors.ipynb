{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in the other notebook, we're making a matrix of movie similarity to other movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in range(1940, 2018):\n",
    "    dfs.append(pd.read_csv('scraped_movies/top_movies_of_%d.csv' % year, encoding = 'cp1252'))\n",
    "movie_data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in range(1940, 2018):\n",
    "    dfs.append(pd.read_csv('scraped_movies/actors_for_top_movies_of_%d.csv' % year, encoding = 'utf-8'))\n",
    "actors = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in range(1940, 2018):\n",
    "    dfs.append(pd.read_csv('scraped_movies/keywords_for_top_movies_of_%d.csv' % year, encoding = 'utf-8'))\n",
    "keywords = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_lookup = pd.Series(movie_data.title)\n",
    "title_lookup.index = movie_data.IMDbId\n",
    "title_lookup = title_lookup.to_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_data.index = range(len(movie_data))\n",
    "actors.index = range(len(actors))\n",
    "keywords.index = range(len(keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can make two matrixes now, one encoding the information about keywords, the other the information about what actors the movies have in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_matrix(df, column_name, countvectoriser, tfidf): \n",
    "    sparse = countvectoriser.fit_transform(pd.Series(df[column_name].fillna('').values))\n",
    "    weighted = tfidf.fit_transform(sparse)    \n",
    "    matrix = weighted.dot(weighted.T)\n",
    "    movies = pd.Series(countvectoriser.get_feature_names())\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "vlad_ = CountVectorizer(tokenizer = lambda x: x.split('|'), min_df = 5)\n",
    "megatron_ = TfidfTransformer()\n",
    "actor_matrix = make_matrix(actors, 'actors', vlad_, megatron_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "vlad = CountVectorizer(tokenizer = lambda x: x.split('|'), min_df = 10)\n",
    "megatron = TfidfTransformer()\n",
    "keyword_matrix = make_matrix(keywords, 'keywords', vlad_, megatron_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where stuff gets kinda wild: Because the two matrixes share dimensionality and encode similar information (which movies are similar to each other), we can sum them together, rather than concatenating them. Then we can apply dimensionality reduction to this matrix that combines the two sets of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta=1, eta=0.1, init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=100, nls_max_iter=2000, random_state=None, shuffle=False,\n",
       "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shrinky = NMF(n_components = 100)\n",
    "\n",
    "both = actor_matrix + keyword_matrix\n",
    "\n",
    "shrinky.fit(both.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "both_shrunk_100 = shrinky.transform(both.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "actors_shrunk_100 = shrinky.transform(actor_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "keywords_shrunk_100 = shrinky.transform(keyword_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the shrunk matrixes contain the same columns, with the same meaning, we can find similar movies based on actors, or based on keywords, or, weirdest of all, we can get the embedding of a movie's keywords, and then find the most similar movies in the actors matrix. In other words, if we know one movie's actors, and another movie's keywords, we can say how similar they are, even though we have no common points of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie = list(keywords.IMDbId.map(title_lookup)).index(\"Alien (1979)\")\n",
    "target = keywords_shrunk_100[movie].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Red Planet (2000)',\n",
       " 'Alien³ (1992)',\n",
       " 'Alien Resurrection (1997)',\n",
       " 'Alien (1979)',\n",
       " 'Dark Star (1974)',\n",
       " 'Lost in Space (1998)',\n",
       " 'Battlefield Earth (2000)',\n",
       " 'Mission to Mars (2000)',\n",
       " 'Pitch Black (2000)',\n",
       " 'Hollow Man (2000)',\n",
       " 'Alien: Covenant (2017)',\n",
       " 'Event Horizon (1997)',\n",
       " 'SpaceCamp (1986)',\n",
       " 'Life (I) (2017)',\n",
       " 'AVP: Alien vs. Predator (2004)',\n",
       " 'Elysium (I) (2013)',\n",
       " 'Riddick (2013)',\n",
       " 'Cosmos (1980– )',\n",
       " 'Aliens (1986)',\n",
       " 'Mama (I) (2013)']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[keywords.IMDbId.map(title_lookup)[i] for i in actors_best_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can make it even stranger! We can make a matrix which has a row for each keyword or actor, and a column for whether that keyword/actor is in a particular movie. Then we can apply the same dimensionality reduction as we learned from before. We end up with an embedding of the single keyword or actor that is compatible with the embedding of movies, actors, or keywords - it's a common language to describe all of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vlad = CountVectorizer(tokenizer = lambda x: x.split('|'), min_df = 5)\n",
    "megatron = TfidfTransformer()\n",
    "\n",
    "sparse = vlad.fit_transform(pd.Series(keywords['keywords'].fillna('').values))\n",
    "weighted = megatron.fit_transform(sparse)\n",
    "shrunk = shrinky.transform(weighted.transpose().toarray())\n",
    "keywords_df = pd.DataFrame(shrunk, index=vlad.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vlad = CountVectorizer(tokenizer = lambda x: x.split('|'), min_df = 10)\n",
    "megatron = TfidfTransformer()\n",
    "\n",
    "sparse = vlad.fit_transform(pd.Series(actors['actors'].fillna('').values))\n",
    "weighted = megatron.fit_transform(sparse)\n",
    "shrunk = shrinky.transform(weighted.transpose().toarray())\n",
    "actors_df = pd.DataFrame(shrunk, index=vlad.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding keywords that go with an actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = actors_df.loc['john wayne'].values.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cowboys-and-indians', 'western-frontier', 'carbine', 'horse-thief',\n",
       "       'yaqui-indian', 'chief', 'buried-to-the-neck', 'stars-and-stripes',\n",
       "       'edited-from-tv-series', 'hung-by-wrists', 'wagon', 'bronco',\n",
       "       'cherokee', 'confederate', 'land-baron', 'monument-valley',\n",
       "       'kiowa-indian', 'reference-to-robert-e.-lee', 'native-american-tribe',\n",
       "       'horse-riding', 'navajo-indian', 'long-range-rifle', 'horse',\n",
       "       'hit-with-a-gun', 'cantina', 'falling-off-a-horse', 'renegade',\n",
       "       'peace-pipe', 'native-american-attack', 'american-civil-war-veteran'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_list = [i for i in np.argsort(cosine_similarity(target, keywords_df))[0][::-1]][:30]\n",
    "keywords_df.iloc[best_list].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding actors that go with a keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = keywords_df.loc['blaxploitation'].values.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clifton powell', 'terrence howard', 'roger guenveur smith',\n",
       "       'tyra ferrell', 'ice-t', 'leonard l. thomas', 'spike lee',\n",
       "       'tamala jones', 'martin lawrence', 'theresa randle', 'bernie mac',\n",
       "       'steve white', 'khandi alexander', 'tommy 'tiny' lister',\n",
       "       'clarence williams iii', 'meagan good', 'ossie davis', 'lela rochon',\n",
       "       'ice cube', 'robert townsend', 'giancarlo esposito', 'antonio fargas',\n",
       "       'sidney poitier', 'ruby dee', 'bill nunn', 'vivica a. fox',\n",
       "       'blair underwood', 'chris tucker', 'lawanda page', 'regina hall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_list = [i for i in np.argsort(cosine_similarity(target, actors_df))[0][::-1]][:30]\n",
    "actors_df.iloc[best_list].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding movies from a combination of actor and keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Men of Honor (2000)',\n",
       " 'Posse (1993)',\n",
       " 'Mandingo (1975)',\n",
       " 'Car Wash (1976)',\n",
       " 'Billy Two Hats (1974)',\n",
       " 'Band of Angels (1957)',\n",
       " 'Little Big Man (1970)',\n",
       " 'Hostiles (2017)',\n",
       " 'The Searchers (1956)',\n",
       " \"Let's Do It Again (1975)\",\n",
       " 'The Brothers (2001)',\n",
       " 'Higher Learning (1995)',\n",
       " 'The Way West (1967)',\n",
       " 'Do the Right Thing (1989)',\n",
       " 'Trooper Hook (1957)',\n",
       " 'Roots (1977– )',\n",
       " 'The Mack (1973)',\n",
       " 'School Daze (1988)',\n",
       " 'McLintock! (1963)',\n",
       " 'The Players Club (1998)',\n",
       " 'The Unforgiven (1960)',\n",
       " 'A Patch of Blue (1965)',\n",
       " 'Hondo (1953)',\n",
       " 'No Way Out (1950)',\n",
       " 'Life (I) (1999)',\n",
       " 'Think Like a Man Too (2014)',\n",
       " 'Barbershop (2002)',\n",
       " 'Geronimo: An American Legend (1993)',\n",
       " \"A Soldier's Story (1984)\",\n",
       " 'The Villain (1979)']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = keywords_df.loc['blaxploitation'].values.reshape(1, -1) + actors_df.loc['john wayne'].values.reshape(1, -1)\n",
    "\n",
    "best_list = [i for i in np.argsort(cosine_similarity(target, both_shrunk_100))[0][::-1]][:30]\n",
    "[keywords.IMDbId.map(title_lookup)[i] for i in best_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
